{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xP1dySpsSMa"
      },
      "source": [
        "# Processamento de Linguagem Natural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5ERBtcAsSMc",
        "outputId": "b5342a74-13e8-4840-9995-55fca2fad77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.7.6\n"
          ]
        }
      ],
      "source": [
        "# Versão da Linguagem Python\n",
        "from platform import python_version\n",
        "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My3z1sXEsSMg"
      },
      "source": [
        "## Seq2seq\n",
        "\n",
        "O Seq2seq foi introduzido pela primeira vez para tradução automática, pelo Google.\n",
        "Antes disso, a tradução funcionava de maneira muito ingênua. Cada palavra que você\n",
        "costumava digitar era convertida para o idioma de destino, sem considerar a gramática e a\n",
        "estrutura da frase. O Seq2seq revolucionou o processo de tradução, utilizando o aprendizado\n",
        "profundo (Deep Learning). Ele não apenas leva em consideração a palavra / entrada atual\n",
        "durante a tradução, mas também sua vizinhança.\n",
        "Atualmente, é usado para uma variedade de aplicações diferentes, como legendas de\n",
        "imagens, modelos de conversação, resumo de texto, tradução, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o nome sugere, seq2seq usa como entrada uma sequência de palavras (sentença\n",
        "ou sentenças) e gera uma sequência de saída de palavras. Faz isso usando a rede neural\n",
        "recorrente (RNN), sendo comum usarmos versões avançadas da RNN, ou seja, LSTM ou GRU\n",
        "(estudadas no curso Deep Learning II). Isso ocorre porque a RNN sofre com o problema da\n",
        "dissipação do gradiente. O modelo LSTM é usado na versão proposta pelo Google. Ele\n",
        "desenvolve o contexto da palavra, recebendo 2 entradas em cada ponto do tempo. Um atual e\n",
        "outro da saída anterior, daí o nome recorrente (a saída entra como entrada).\n",
        "O Seq2seq possui principalmente dois componentes: codificador e decodificador, e,\n",
        "portanto, às vezes é chamado de Rede Codificador-Decodificador.\n",
        "\n",
        "* **Codificador:** Utiliza camadas de rede neural profunda e converte as palavras de entrada\n",
        "em vetores ocultos correspondentes. Cada vetor representa a palavra atual e o contexto da\n",
        "palavra.\n",
        "\n",
        "* **Decodificador:** É semelhante ao codificador. Toma como entrada o vetor oculto gerado\n",
        "pelo codificador, seus próprios estados ocultos e a palavra atual para produzir o próximo vetor\n",
        "oculto e finalmente prever a próxima palavra.\n",
        "\n",
        "Além desses dois elementos, muitas otimizações levaram a outros componentes do\n",
        "seq2seq:\n",
        "\n",
        "* **Attention:** A entrada para o decodificador é um único vetor que deve armazenar todas as\n",
        "informações sobre o contexto. Isso se torna um problema com grandes sequências. Portanto, o\n",
        "mecanismo de atenção é aplicado, permitindo que o decodificador observe a sequência de\n",
        "entrada seletivamente.\n",
        "\n",
        "* **Beam Search:** A palavra com maior probabilidade é selecionada como saída pelo decodificador.\n",
        "Mas isso nem sempre produz os melhores resultados, devido ao problema básico dos\n",
        "algoritmos gananciosos. Portanto, a pesquisa por feixe é aplicada, o que sugere possíveis\n",
        "traduções em cada etapa. Isso é feito criando uma árvore dos melhores resultados.\n",
        "\n",
        "* **Bucketing:** Sequências de comprimento variável são possíveis em um modelo seq2seq, devido\n",
        "ao preenchimento de 0, que é feito na entrada e na saída. No entanto, se o comprimento\n",
        "máximo definido por nós for 100 e a sentença tiver apenas 3 palavras, isso causará enorme\n",
        "desperdício de espaço. Então, usamos o conceito de Bucketing. Criamos variáveis de tamanhos\n",
        "diferentes, como (4, 8) (8, 15) e assim por diante, onde 4 é o comprimento máximo de entrada\n",
        "definido por nós e 8 é o comprimento máximo de saída definido."
      ],
      "metadata": {
        "id": "uEX20i06tNBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnyvGglUsSMg"
      },
      "outputs": [],
      "source": [
        "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
        "# pip install -U nome_pacote\n",
        "\n",
        "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
        "# !pip install torch==1.5.0\n",
        "\n",
        "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
        "\n",
        "# Instala o pacote watermark.\n",
        "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3vRDmdgsSMh"
      },
      "outputs": [],
      "source": [
        "# Instala o PyTorch\n",
        "!pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkRq4QJKsSMh"
      },
      "outputs": [],
      "source": [
        "# O pacote torchtext fornece diversos datasets e funções para PLN\n",
        "# https://torchtext.readthedocs.io/en/latest/index.html\n",
        "!pip install -q torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61kViVTEsSMh"
      },
      "outputs": [],
      "source": [
        "# Instala o spacy\n",
        "!pip install -q spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvvm2iHQsSMi"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import time\n",
        "import spacy\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni7rZilQsSMi",
        "outputId": "0bd41028-7e65-46c8-f565-0f01788f99ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spacy     2.2.4\n",
            "numpy     1.18.4\n",
            "torch     1.5.0\n",
            "torchtext 0.6.0\n",
            "Data Science Academy\n"
          ]
        }
      ],
      "source": [
        "# Versões dos pacotes usados neste jupyter notebook\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Data Science Academy\" --iversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjmMUXxnsSMj"
      },
      "source": [
        "Nota: O treinamento do modelo deste estudo de caso é computacionalmente intensivo e por isso treinamos o modelo no Titan, o super servidor da DSA, com 3 GPUs e 128 GB de Memória RAM. O acesso a esse servidor é gratuito para alunos das Formações:\n",
        "\n",
        "- <a href=\"https://www.datascienceacademy.com.br/pages/formacao-inteligencia-artificial\">Formação Inteligência Artificial</a>\n",
        "- <a href=\"https://www.datascienceacademy.com.br/pages/formacao-ia-aplicada-a-medicina\">Formação Inteligência Artificial Aplicada à Medicina</a>\n",
        "- <a href=\"https://www.datascienceacademy.com.br/pages/formacao-engenheiro-blockchain\">Formação Engenheiro Blockchain</a>\n",
        "\n",
        "O treinamento pode ser feito em um computador apenas com CPU. O tempo de treinamento será um pouco maior, mas o estudo de caso poderá ser executado sem problemas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUp2rQFnsSMk"
      },
      "outputs": [],
      "source": [
        "# Aqui definimos o device que será usado para treinar o modelo\n",
        "# Se pelo menos uma GPU estiver disponível, usaremos o device 'cuda' (nome da plataforma da Nvidia para GPU)\n",
        "# Se não tiver GPU, usaremos a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaSWZ_0FsSMl"
      },
      "source": [
        "Abaixo a descrição das GPUs do servidor da DSA. O comando abaixo funcionará somente se a plataforma CUDA da Nivida estiver instalada no computador. Se quiser conhecer mais sobre a plataforma CUDA, acesse aqui:\n",
        "\n",
        "https://developer.nvidia.com/cuda-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8ZxGkOzsSMm",
        "outputId": "f330b7f9-05ad-4579-fd49-4e18f16410da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 21 21:49:41 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  TITAN X (Pascal)    On   | 00000000:05:00.0 Off |                  N/A |\r\n",
            "| 23%   41C    P8     9W / 250W |    125MiB / 12194MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "|   1  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\r\n",
            "| 23%   38C    P8     9W / 250W |     12MiB / 11178MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "|   2  TITAN RTX           On   | 00000000:0B:00.0 Off |                  N/A |\r\n",
            "| 41%   39C    P8    13W / 280W |     12MiB / 24220MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|    0      1578      G   /usr/lib/xorg/Xorg                            39MiB |\r\n",
            "|    0      1614      G   /usr/bin/gnome-shell                          72MiB |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ]
        }
      ],
      "source": [
        "# GPUs no servidor da DSA\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjepNrgMsSMm"
      },
      "source": [
        "### Carregando os Dicionários\n",
        "\n",
        "Precisamos instalar os dicionários dos idiomas que serão usados para treinar o modelo. Aqui você encontra detalhes sobre os datasets:\n",
        "\n",
        "https://www.statmt.org/wmt16/multimodal-task.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQycdhkfsSMo",
        "outputId": "1a029315-4506-4d95-91a0-e63c3a1974ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200210)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.42.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/dmpm/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/home/dmpm/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
            "/home/dmpm/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ],
      "source": [
        "# Download do dicionário em inglês\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6YDfpiwsSMp",
        "outputId": "04474804-2662-452e-821a-38cdb119d3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.42.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.22.0)\n",
            "Requirement already satisfied: setuptools in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (45.2.0.post20200210)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/dmpm/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.25.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/dmpm/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/home/dmpm/anaconda3/lib/python3.7/site-packages/de_core_news_sm -->\n",
            "/home/dmpm/anaconda3/lib/python3.7/site-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ]
        }
      ],
      "source": [
        "# Download do dicionário em alemão\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdUBz8qusSMp"
      },
      "source": [
        "Agora carregamos os dicionários na memória."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJyv5K59sSMq"
      },
      "outputs": [],
      "source": [
        "# Carregando os dicionários\n",
        "spacy_german = spacy.load('de')\n",
        "spacy_english = spacy.load('en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GhuULO3sSMq"
      },
      "source": [
        "Vamos criar duas funções para tokenização dos dicionários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pl8E2MPsSMq"
      },
      "outputs": [],
      "source": [
        "# Função para tokenização do dicionário em inglês\n",
        "def tokenize_english(text):\n",
        "    return [token.text for token in spacy_english.tokenizer(text)][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSFt8vnfsSMr"
      },
      "outputs": [],
      "source": [
        "# Função para tokenização do dicionário em alemão\n",
        "def tokenize_german(text):\n",
        "    return [token.text for token in spacy_german.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waiSjlixsSMs"
      },
      "source": [
        "Precisamos agora criar a fonte e o destino, ou seja, o idioma fonte e o idioma destino para nosso tradutor.\n",
        "\n",
        "Nosso modelo deverá fazer a tradução do inglês para o alemão. Inglês será a fonte (SOURCE) e Alemão será o destino (TARGET)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvGdmpjPsSMs"
      },
      "outputs": [],
      "source": [
        "# Idioma de origem\n",
        "SOURCE = Field(tokenize = tokenize_english, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bsehdYtsSMt"
      },
      "outputs": [],
      "source": [
        "# Idioma de destino\n",
        "TARGET = Field(tokenize = tokenize_german, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBh5LBiPsSMt"
      },
      "outputs": [],
      "source": [
        "# Usamos a split() do pacote Multi30k do torchtext para separar os dicionários em SOURCE e TARGET\n",
        "# e então em treino, validação e teste\n",
        "# Obs: Será feito o download dos dados no pacote Multi30k\n",
        "dados_treino, dados_valid, dados_teste = Multi30k.splits(exts = ('.en', '.de'), fields = (SOURCE, TARGET))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01q9FvCAsSMt",
        "outputId": "168e12b5-0b5f-4f02-ad9b-fbd85c44115f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.', 'bushes', 'many', 'near', 'outside', 'are', 'males', 'white', ',', 'young', 'two']\n",
            "['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n"
          ]
        }
      ],
      "source": [
        "# Visualizando os dados de treino, SOURCE e TARGET\n",
        "print(dados_treino.examples[0].src)\n",
        "print(dados_treino.examples[0].trg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgo0E9L1sSMu",
        "outputId": "48f5293b-1194-4e5f-bfc6-7bf5403c10f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do Dataset de Treino: 29000\n",
            "Tamanho do Dataset de Validação: 1014\n",
            "Tamanho do Dataset de Teste: 1000\n"
          ]
        }
      ],
      "source": [
        "print(\"Tamanho do Dataset de Treino: \" + str(len(dados_treino.examples)))\n",
        "print(\"Tamanho do Dataset de Validação: \" + str(len(dados_valid.examples)))\n",
        "print(\"Tamanho do Dataset de Teste: \" + str(len(dados_teste.examples)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI42rvPwsSMu"
      },
      "outputs": [],
      "source": [
        "# Vamos criar os vocabulários de SOURCE  e TARGET\n",
        "SOURCE.build_vocab(dados_treino, min_freq = 2)\n",
        "TARGET.build_vocab(dados_treino, min_freq = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LcZVQb1sSMu",
        "outputId": "54767d51-3ec1-4497-9b69-5d8eed07b6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do Vocabulário em Inglês (SOURCE): 5893\n",
            "Tamanho do Vocabulário em Alemão (TARGET): 7855\n"
          ]
        }
      ],
      "source": [
        "# Print do tamanho dos vocabulários\n",
        "print(\"Tamanho do Vocabulário em Inglês (SOURCE): \" + str(len(SOURCE.vocab)))\n",
        "print(\"Tamanho do Vocabulário em Alemão (TARGET): \" + str(len(TARGET.vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm3_Op2vsSMv"
      },
      "source": [
        "### Construindo o Modelo\n",
        "\n",
        "Criaremos 3 classes:\n",
        "\n",
        "- Encoder\n",
        "- Decoder\n",
        "- Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QKkq8WrsSMv"
      },
      "outputs": [],
      "source": [
        "# Classe para o Encoder\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    # Método construtor\n",
        "    def __init__(self, input_dims, emb_dims, hid_dims, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        # Camadas do modelo\n",
        "        self.hid_dims = hid_dims\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dims, emb_dims)\n",
        "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Método forward para o treinamento\n",
        "    def forward(self, src):\n",
        "\n",
        "        # Execução do modelo\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (h, cell) = self.rnn(embedded)\n",
        "\n",
        "        return h, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43nNyvNysSMv"
      },
      "outputs": [],
      "source": [
        "# Classe para o Decoder\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    # Método construtor\n",
        "    def __init__(self, output_dims, emb_dims, hid_dims, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        # Camadas do modelo\n",
        "        self.output_dims = output_dims\n",
        "        self.hid_dims = hid_dims\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dims, emb_dims)\n",
        "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
        "        self.fc_out = nn.Linear(hid_dims, output_dims)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Método forward para o treinamento\n",
        "    def forward(self, input, h, cell):\n",
        "\n",
        "        # Execução do modelo\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (h, cell) = self.rnn(embedded, (h, cell))\n",
        "        pred = self.fc_out(output.squeeze(0))\n",
        "\n",
        "        return pred, h, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8p_faszsSMw"
      },
      "outputs": [],
      "source": [
        "# Classe para o modelo Seq2Seq\n",
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    # Método construtor\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        # Componentes do modelo\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    # Método forward para o treinamento\n",
        "    def forward(self, src, trg, teacher_forcing_rate = 0.5):\n",
        "\n",
        "        # Execução do modelo\n",
        "        batch_size = trg.shape[1]\n",
        "        target_length = trg.shape[0]\n",
        "        target_vocab_size = self.decoder.output_dims\n",
        "        outputs = torch.zeros(target_length, batch_size, target_vocab_size).to(self.device)\n",
        "        h, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "\n",
        "        for t in range(1, target_length):\n",
        "\n",
        "            output, h, cell = self.decoder(input, h, cell)\n",
        "            outputs[t] = output\n",
        "            top = output.argmax(1)\n",
        "            input = trg[t] if (random.random() < teacher_forcing_rate) else top\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwqT2CVUsSMw"
      },
      "source": [
        "Vamos definir alguns hiperparâmetros e os gerados de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA2wHwdqsSMw"
      },
      "outputs": [],
      "source": [
        "# Hiperparâmetros\n",
        "batch_size = 32\n",
        "input_dimensions = len(SOURCE.vocab)\n",
        "output_dimensions = len(TARGET.vocab)\n",
        "encoder_embedding_dimensions = 256\n",
        "decoder_embedding_dimensions = 256\n",
        "hidden_layer_dimensions = 512\n",
        "num_layers = 2\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "epochs = 20\n",
        "grad_clip = 1\n",
        "lowest_validation_loss = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66Jr_yNEsSMx"
      },
      "outputs": [],
      "source": [
        "# Geradores de dados\n",
        "iterador_treino, iterador_valid, iterador_teste = BucketIterator.splits((dados_treino, dados_valid, dados_teste),\n",
        "                                                                        batch_size = batch_size,\n",
        "                                                                        device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZM7-_i8sSMx"
      },
      "source": [
        "Aqui nós criamos o encoder, decoder e o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS-pIEYUsSM5"
      },
      "outputs": [],
      "source": [
        "# Instância do Encoder\n",
        "encod = Encoder(input_dimensions,\n",
        "                encoder_embedding_dimensions,\n",
        "                hidden_layer_dimensions,\n",
        "                num_layers,\n",
        "                encoder_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZdVBaHlsSM5"
      },
      "outputs": [],
      "source": [
        "# Instância do Decoder\n",
        "decod = Decoder(output_dimensions,\n",
        "                decoder_embedding_dimensions,\n",
        "                hidden_layer_dimensions,\n",
        "                num_layers,\n",
        "                decoder_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U1dzOqAsSM5"
      },
      "outputs": [],
      "source": [
        "# Instância do Modelo\n",
        "modelo = Seq2Seq(encod, decod, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtdqKwhssSM5",
        "outputId": "4d51bbf9-c1d7-42cf-ae75-235f5b43d244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Modelo criado\n",
        "modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezoDjYKusSM6"
      },
      "source": [
        "Vamos definir a função de inicalização dos pesos, função de custo e otimizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmYiham3sSM6"
      },
      "outputs": [],
      "source": [
        "# Precisamos de uma função para inicializar os pesos da rede neural\n",
        "def inicializa_pesos(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.1, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIL7T9YdsSM6",
        "outputId": "92c604fc-94b6-4399-e5c0-1d4bea8cb75f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Incluímos a função de inicialização dos pesos no modelo\n",
        "modelo.apply(inicializa_pesos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RbtVFLdsSM7"
      },
      "outputs": [],
      "source": [
        "# Definimos a função de custo para calcular o erro do modelo\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TARGET.vocab.stoi[TARGET.pad_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgKHy236sSM7"
      },
      "outputs": [],
      "source": [
        "# Criamos o otimizador para atualizar os pesos do modelo a cada passada de treinamento\n",
        "optimizer = optim.Adam(modelo.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcSw9Fo-sSM7"
      },
      "source": [
        "Embora não seja obrigatório, criar funções para treino e avaliação do modelo ajuda a modularizar nosso processo de treinamento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPxX6IsHsSM8"
      },
      "outputs": [],
      "source": [
        "# Função para treinar o modelo\n",
        "def treina_modelo(modelo, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    # Inicia o método de treinamento\n",
        "    modelo.train()\n",
        "\n",
        "    # Inicializa o erro da epoch\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Loop pelo iterador (gerador de dados)\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        # Coletamos dados fonte e destino\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        # Zeramos os gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Fazemos as previsões com o modelo\n",
        "        output = modelo(src, trg)\n",
        "\n",
        "        # Ajustamos o shape das previsões\n",
        "        output_dims = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dims)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        # Calculamos o erro do modelo\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # Iniciamos o backpropgation\n",
        "        loss.backward()\n",
        "\n",
        "        # Calculamos os gradientes da derivada para atualização dos pesos\n",
        "        torch.nn.utils.clip_grad_norm_(modelo.parameters(), clip)\n",
        "\n",
        "        # Aplicamos a atualização dos pesos\n",
        "        optimizer.step()\n",
        "\n",
        "        # Armazenamos o erro da epoch\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKbwEzBvsSM8"
      },
      "outputs": [],
      "source": [
        "# Função para avaliar o modelo\n",
        "def avalia_modelo(modelo, iterator, criterion):\n",
        "\n",
        "    # Inicia função de avaiação\n",
        "    modelo.eval()\n",
        "\n",
        "    # Inicializa o erro da epoch\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Vamos fazer as previsões com o modelo\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Loop pelo iterador (gerador de dados)\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Extrai fonte e destino\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            # Previsão com o modelo\n",
        "            output = modelo(src, trg, 0)\n",
        "\n",
        "            # Ajusta as dimensões das previsões\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # Calcula o erro do modelo\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # Armazena o erro na epoch\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wydqk9RrsSM9"
      },
      "source": [
        "### Treinando o Modelo\n",
        "\n",
        "O treinamento do modelo é demorado. Seja paciente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvE5UKmisSM9",
        "outputId": "2d090e76-98b5-4d8a-8b27-e3c963160613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 48.0s\n",
            "\tErro em Treino: 4.7076\n",
            "\t Erro em Validação: 4.6512\n",
            "Epoch: 02 | Time: 47.0s\n",
            "\tErro em Treino: 3.9973\n",
            "\t Erro em Validação: 4.3468\n",
            "Epoch: 03 | Time: 47.0s\n",
            "\tErro em Treino: 3.6368\n",
            "\t Erro em Validação: 4.0514\n",
            "Epoch: 04 | Time: 48.0s\n",
            "\tErro em Treino: 3.3807\n",
            "\t Erro em Validação: 3.8883\n",
            "Epoch: 05 | Time: 48.0s\n",
            "\tErro em Treino: 3.1684\n",
            "\t Erro em Validação: 3.8140\n",
            "Epoch: 06 | Time: 48.0s\n",
            "\tErro em Treino: 2.9915\n",
            "\t Erro em Validação: 3.6792\n",
            "Epoch: 07 | Time: 47.0s\n",
            "\tErro em Treino: 2.8233\n",
            "\t Erro em Validação: 3.6726\n",
            "Epoch: 08 | Time: 48.0s\n",
            "\tErro em Treino: 2.6837\n",
            "\t Erro em Validação: 3.6291\n",
            "Epoch: 09 | Time: 48.0s\n",
            "\tErro em Treino: 2.5523\n",
            "\t Erro em Validação: 3.6190\n",
            "Epoch: 10 | Time: 47.0s\n",
            "\tErro em Treino: 2.4393\n",
            "\t Erro em Validação: 3.5998\n",
            "Epoch: 11 | Time: 47.0s\n",
            "\tErro em Treino: 2.3307\n",
            "\t Erro em Validação: 3.5683\n",
            "Epoch: 12 | Time: 48.0s\n",
            "\tErro em Treino: 2.2307\n",
            "\t Erro em Validação: 3.5983\n",
            "Epoch: 13 | Time: 48.0s\n",
            "\tErro em Treino: 2.1253\n",
            "\t Erro em Validação: 3.5880\n",
            "Epoch: 14 | Time: 47.0s\n",
            "\tErro em Treino: 2.0154\n",
            "\t Erro em Validação: 3.6639\n",
            "Epoch: 15 | Time: 48.0s\n",
            "\tErro em Treino: 1.9392\n",
            "\t Erro em Validação: 3.6356\n",
            "Epoch: 16 | Time: 48.0s\n",
            "\tErro em Treino: 1.8669\n",
            "\t Erro em Validação: 3.6467\n",
            "Epoch: 17 | Time: 48.0s\n",
            "\tErro em Treino: 1.7866\n",
            "\t Erro em Validação: 3.7214\n",
            "Epoch: 18 | Time: 48.0s\n",
            "\tErro em Treino: 1.7091\n",
            "\t Erro em Validação: 3.7471\n",
            "Epoch: 19 | Time: 47.0s\n",
            "\tErro em Treino: 1.6635\n",
            "\t Erro em Validação: 3.7931\n",
            "Epoch: 20 | Time: 48.0s\n",
            "\tErro em Treino: 1.6003\n",
            "\t Erro em Validação: 3.8183\n"
          ]
        }
      ],
      "source": [
        "# Loop pelo número de epochs para treinar o modelo\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Grava o tempo quando começamos\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Treinamento\n",
        "    train_loss = treina_modelo(modelo, iterador_treino, optimizer, criterion, grad_clip)\n",
        "\n",
        "    # Validação\n",
        "    valid_loss = avalia_modelo(modelo, iterador_valid, criterion)\n",
        "\n",
        "    # Grava o tempo quando finalizamos\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Verificamos o erro mínimo e então salvamos o modelo fazendo um checkpoint do modelo com melhor performance\n",
        "    if valid_loss < lowest_validation_loss:\n",
        "        lowest_validation_loss = valid_loss\n",
        "        torch.save(modelo.state_dict(), 'modelos/seq2seq.pt')\n",
        "\n",
        "    # Print\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {np.round(end_time-start_time,0)}s')\n",
        "    print(f'\\tErro em Treino: {train_loss:.4f}')\n",
        "    print(f'\\t Erro em Validação: {valid_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffS1jn0msSM9"
      },
      "source": [
        "### Avaliando o Modelo\n",
        "\n",
        "Com o modelo treinado, avaliamos com dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAYNqgKasSM-",
        "outputId": "e45c271a-b2c5-43b4-d3cc-3b2df6d06121"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carregamos o modelo treinado\n",
        "modelo.load_state_dict(torch.load('modelos/seq2seq.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOzaW46ksSM-"
      },
      "outputs": [],
      "source": [
        "# Avaliamos o modelo\n",
        "test_loss = avalia_modelo(modelo, iterador_teste, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qmt3nsZsSM-",
        "outputId": "5fd53104-7d47-4753-dfa8-80405f0d6e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erro em Teste: 3.5024\n"
          ]
        }
      ],
      "source": [
        "# Print\n",
        "print(f'Erro em Teste: {test_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Wt5_LLsSM_"
      },
      "source": [
        "### Traduzindo Idioma\n",
        "\n",
        "Modelo treinado e avaliado, vamos usá-lo para o fim para o qual ele foi criado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0oMub3HsSM_"
      },
      "outputs": [],
      "source": [
        "# Função para tradução de idioma em 5 sentenças\n",
        "def traduz_idioma(modelo, iterator, limit = 5):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Loop pelo iterador\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Enquanto estivermos dentro do limite, vamos fazendo tradução\n",
        "            if i < limit :\n",
        "\n",
        "                # Extraímos SOURCE e TARGET\n",
        "                # Fazemos isso para poder comparar a tradução correta com a previsão\n",
        "                src = batch.src\n",
        "                trg = batch.trg\n",
        "\n",
        "                # Previsão do modelo\n",
        "                output = modelo(src, trg, 0)\n",
        "\n",
        "                # Todas as previsões\n",
        "                preds = torch.tensor([[torch.argmax(x).item()] for x in output])\n",
        "\n",
        "                # Prints\n",
        "                print('Texto de Origem em Inglês: ' + str([SOURCE.vocab.itos[x] for x in src][1:-1][::-1]))\n",
        "                print('Texto de Destino em Alemão (Valor Esperado): ' + str([TARGET.vocab.itos[x] for x in trg][1:-1]))\n",
        "                print('Texto de Destino em Alemão (Valor Previsto): ' + str([TARGET.vocab.itos[x] for x in preds][1:-1]))\n",
        "                print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmvAGhzgsSM_"
      },
      "outputs": [],
      "source": [
        "# Vamos gerar texto randômico a partir dos dados disponíveis\n",
        "_, _, iterador_translate = BucketIterator.splits((dados_treino, dados_valid, dados_teste),\n",
        "                                                 batch_size = 1,\n",
        "                                                 device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nHDS7G_sSNA",
        "outputId": "0df6177b-2d5d-44e1-b783-9da6eddfefa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto de Origem em Inglês: ['two', 'men', 'wearing', 'hats', '.']\n",
            "Texto de Destino em Alemão (Valor Esperado): ['zwei', 'männer', 'mit', 'mützen', '.']\n",
            "Texto de Destino em Alemão (Valor Previsto): ['zwei', 'männer', 'mit', 'schwarzen', 'haaren']\n",
            "\n",
            "\n",
            "Texto de Origem em Inglês: ['young', 'woman', 'climbing', 'rock', 'face']\n",
            "Texto de Destino em Alemão (Valor Esperado): ['junge', 'frau', 'klettert', 'auf', 'felswand']\n",
            "Texto de Destino em Alemão (Valor Previsto): ['eine', 'junge', 'frau', 'klettert', 'eine']\n",
            "\n",
            "\n",
            "Texto de Origem em Inglês: ['a', 'woman', 'is', 'playing', 'volleyball', '.']\n",
            "Texto de Destino em Alemão (Valor Esperado): ['eine', 'frau', 'spielt', 'volleyball', '.']\n",
            "Texto de Destino em Alemão (Valor Previsto): ['eine', 'frau', 'spielt', 'volleyball', '.']\n",
            "\n",
            "\n",
            "Texto de Origem em Inglês: ['three', 'men', 'are', 'walking', 'up', 'hill', '.']\n",
            "Texto de Destino em Alemão (Valor Esperado): ['drei', 'männer', 'gehen', 'bergauf', '.']\n",
            "Texto de Destino em Alemão (Valor Previsto): ['drei', 'männer', 'gehen', 'durch', 'einen']\n",
            "\n",
            "\n",
            "Texto de Origem em Inglês: ['an', 'army', 'officer', 'is', 'inspecting', 'something', '.']\n",
            "Texto de Destino em Alemão (Valor Esperado): ['ein', '<unk>', 'inspiziert', 'etwas', '.']\n",
            "Texto de Destino em Alemão (Valor Previsto): ['ein', '<unk>', 'schaut', 'in', 'die']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tradução de idioma\n",
        "saida = traduz_idioma(modelo, iterador_translate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsFUl3tXsSNA"
      },
      "source": [
        "Parabéns! Aí está está seu tradutor de texto com Machine Learning e PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iAIP_54sSNA"
      },
      "source": [
        "# Fim"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}